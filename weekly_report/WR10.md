Progress:
* Further investigated the low utilization issue. I used an ideal vector instruction dispatcher (other scalar instructions are executed by the spike simulator) to ensure that Ara gets one instruction per cycle. The results show that MatMul's performance can be improved by 3x with 16 lanes. FPU utilization improved from 17% to 50%, and the factor preventing FPU utilization from increasing seems to be the latency of the VRF reads.
* Proposed the new instructions and hardware modification needed for the 'broadcast' solution I mentioned last week. Also I wrote a new MatMul program with those new instructions.
Learned how to add custom instructions to the RISC-V GCC compiler.

Next Week:
* Simulate the benchmark again with larger VRF and different model sizes.
* Continue to explore new architectures that address low utilization issue. My advisors suggested architectures like TPU and multi-ara.
